#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
train_rl.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Entrena un â€œfiltroâ€ PPO que decide aceptar o rechazar las seÃ±ales generadas
por un modelo LSTM.  DiseÃ±ado para ejecutarse de forma autÃ³noma en Vertex AI
(CustomJob) o en cualquier entorno con acceso a GCS.

Correciones v2025-06-04 ğŸ’«
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢  AÃ±adidas importaciones de google-cloud (storage / service_account).
â€¢  Se unificÃ³ la inicializaciÃ³n de GPU y mixed-precision.
â€¢  Sanitizado de caracteres y comentarios a UTF-8.
â€¢  Validaciones mÃ¡s estrictas sobre shapes y contenido de los arrays .npz.
â€¢  Limpieza de memoria explÃ­cita y mensajes de log mÃ¡s claros.
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports estÃ¡ndar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import argparse
import gc
import json
import os
import random
import sys
import tempfile
import warnings
from datetime import datetime
from pathlib import Path
from typing import Tuple

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ imports de terceros â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import numpy as np
import pandas as pd
import tensorflow as tf
from google.cloud import storage
from google.oauth2 import service_account
from gymnasium import Env, spaces
from joblib import load as joblib_load
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ configuraciÃ³n global â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore", category=FutureWarning)

SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)
os.environ.setdefault("TF_DETERMINISTIC_OPS", "1")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ GPU & mixed precision â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    gpus = tf.config.list_physical_devices("GPU")
    if gpus:
        for g in gpus:
            tf.config.experimental.set_memory_growth(g, True)
        tf.keras.mixed_precision.set_global_policy("mixed_float16")
        print("ğŸš€  GPU(s) disponibles y policy mixed-precision activada.")
    else:
        print("â„¹ï¸  No se detectaron GPU; se usarÃ¡ CPU.")
except Exception as e:
    print(f"âš ï¸  No se pudo configurar GPU/mixed-precision: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers de GCS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _gcs_client():
    """Devuelve un cliente de GCS respetando GOOGLE_APPLICATION_CREDENTIALS."""
    creds_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if creds_path and Path(creds_path).exists():
        creds = service_account.Credentials.from_service_account_file(creds_path)
        return storage.Client(credentials=creds)
    return storage.Client()

def download_gs(uri: str) -> Path:
    """Descarga `gs://â€¦` a un tmp local y devuelve la ruta local."""
    bucket_name, blob_name = uri[5:].split("/", 1)
    local_path = Path(tempfile.mkdtemp()) / Path(blob_name).name
    _gcs_client().bucket(bucket_name).blob(blob_name).download_to_filename(local_path)
    print(f"ğŸ“¥  Descargado {uri} â†’ {local_path}")
    return local_path

def upload_gs(local: Path, uri: str):
    """Sube un archivo local a `gs://â€¦`."""
    bucket_name, blob_name = uri[5:].split("/", 1)
    _gcs_client().bucket(bucket_name).blob(blob_name).upload_from_filename(str(local))
    print(f"â˜ï¸  Subido {local} â†’ {uri}")

def as_local(path: str) -> Path:
    """Si es GCS descarga; si es local valida existencia."""
    if path.startswith("gs://"):
        return download_gs(path)
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(f"Ruta local no encontrada: {path}")
    return p

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
parser = argparse.ArgumentParser(description="Entrena un filtro PPO sobre las seÃ±ales LSTM")
parser.add_argument("--model",      required=True, help="gs://â€¦ modelo LSTM (.h5)")
parser.add_argument("--scaler",     required=True, help="gs://â€¦ scaler (.pkl)")
parser.add_argument("--params",     required=True, help="gs://â€¦ hiperparÃ¡metros JSON")
parser.add_argument("--rl-data",    required=True, help="gs://â€¦ datos .npz (prepare_rl_data)")
parser.add_argument("--output-bucket", default="trading-ai-models-460823",
                    help="Bucket GCS donde subir el modelo PPO")
parser.add_argument("--tensorboard-log-dir", default=None,
                    help="gs://â€¦ carpeta para logs TensorBoard (opcional)")
args = parser.parse_args()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ carga de artefactos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
hp_path      = as_local(args.params)
hp           = json.loads(hp_path.read_text())
PAIR         = hp["pair"]
TF           = hp["timeframe"]
TICK         = 0.01 if PAIR.endswith("JPY") else 0.0001
ATR_LEN      = hp.get("atr_len", 14)

lstm_model   = tf.keras.models.load_model(as_local(args.model), compile=False)
scaler       = joblib_load(as_local(args.scaler))

# capa de embedding
if len(lstm_model.layers) < 2:  # sanity-check
    sys.exit("âŒ  El modelo LSTM no tiene suficientes capas para extraer embedding.")
emb_model = tf.keras.Model(lstm_model.input, lstm_model.layers[-2].output)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ carga de datos RL (.npz) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
npz_path = as_local(args.rl_data)
try:
    npz = np.load(npz_path)
    OBS       = npz["obs"].astype(np.float32)
    RAW_PNL   = npz["raw"].astype(np.float32)     # seÃ±al PnL por tick
    CLOSES    = npz["closes"].astype(np.float32)
except KeyError as e:
    sys.exit(f"âŒ  Faltan claves en .npz: {e}")
if not (len(OBS) == len(RAW_PNL) == len(CLOSES) > 0):
    sys.exit("âŒ  Los arrays obs/raw/closes estÃ¡n vacÃ­os o con longitudes distintas.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ entorno Gymnasium â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class SignalFilterEnv(Env):
    """Entorno mÃ­nimo para filtrar seÃ±ales LSTM con PPO."""
    metadata = {"render.modes": []}

    def __init__(self, obs: np.ndarray, pnl: np.ndarray):
        super().__init__()
        self._obs = obs
        self._pnl = pnl
        self._max = len(obs) - 1
        self.action_space      = spaces.Discrete(2)  # 0-reject, 1-accept
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf,
                                            shape=(obs.shape[1],), dtype=np.float32)
        self._step = 0

    def reset(self, *, seed=None, options=None):
        super().reset(seed=seed)
        self._step = 0
        return self._obs[0], {}

    def step(self, action: int):
        reward = self._pnl[self._step] if action == 1 else 0.0
        if action == 1 and reward == 0.0:
            reward = hp.get("penalty_useless_action", -0.001)

        self._step += 1
        done = self._step > self._max
        next_obs = np.zeros_like(self._obs[0]) if done else self._obs[self._step]
        return next_obs, reward, done, False, {}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ entrenamiento PPO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print(f"ğŸ‹ï¸  Entrenando PPO para {PAIR}/{TF} â€¦")
env     = DummyVecEnv([lambda: SignalFilterEnv(OBS, RAW_PNL)])
ppo_cfg = hp.get("ppo_hyperparameters", {})
total_ts = int(hp.get("total_timesteps", 500_000))

model = PPO(
    policy           = ppo_cfg.get("policy", "MlpPolicy"),
    env              = env,
    learning_rate    = ppo_cfg.get("learning_rate", 2e-4),
    n_steps          = ppo_cfg.get("n_steps", 2048),
    batch_size       = ppo_cfg.get("batch_size", 512),
    n_epochs         = ppo_cfg.get("n_epochs", 10),
    gamma            = ppo_cfg.get("gamma", 0.99),
    gae_lambda       = ppo_cfg.get("gae_lambda", 0.95),
    clip_range       = ppo_cfg.get("clip_range", 0.2),
    ent_coef         = ppo_cfg.get("ent_coef", 0.0),
    vf_coef          = ppo_cfg.get("vf_coef", 0.5),
    max_grad_norm    = ppo_cfg.get("max_grad_norm", 0.5),
    seed             = SEED,
    verbose          = 1,
    tensorboard_log  = args.tensorboard_log_dir
)

model.learn(total_timesteps=total_ts, progress_bar=True)
print("âœ…  Entrenamiento PPO finalizado.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ guardado & subida a GCS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
timestamp = datetime.utcnow().strftime("%Y%m%d-%H%M%S")
local_dir = Path(tempfile.mkdtemp())
out_file  = local_dir / "ppo_filter_model.zip"
model.save(out_file)

gcs_path  = (f"gs://{args.output_bucket}/models/RL/"
             f"{PAIR}/{TF}/{timestamp}/ppo_filter_model.zip")
upload_gs(out_file, gcs_path)

print(f"ğŸ‰  Script finalizado. Modelo disponible en: {gcs_path}")
gc.collect()
