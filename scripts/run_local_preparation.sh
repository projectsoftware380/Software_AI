#!/bin/bash
# ---------------------------------------------------------------------
# run_local_preparation.sh: Ejecuta la preparaci√≥n de datos localmente.
# ---------------------------------------------------------------------
#
# Este script invoca el componente de preparaci√≥n de datos para que se
# ejecute en la m√°quina local. Descargar√° los datos ingeridos desde GCS,
# los procesar√° y subir√° los datos preparados de nuevo a GCS.
#
# Requisitos:
# - Haber ejecutado previamente `run_local_ingestion.sh`.
# - Tener Google Cloud SDK autenticado.

set -e

# --- Configuraci√≥n ---
export PROJECT_ID="$(gcloud config get-value project)"
export PAIR="EURUSD"
export TIMEFRAME="m1"
export YEARS_TO_KEEP=10
export HOLDOUT_MONTHS=6

# --- Rutas de GCS ---
# La ruta de entrada debe coincidir con la salida de `run_local_ingestion.sh`
export INPUT_GCS_PATH="gs://${PROJECT_ID}-vertex-ai-pipeline-assets/data/ingested/${PAIR}/${TIMEFRAME}/dukascopy_${PAIR}_${TIMEFRAME}.parquet"

# La ruta base de salida para los datos preparados
export OUTPUT_GCS_BASE_PATH="gs://${PROJECT_ID}-vertex-ai-pipeline-assets/data/prepared"

# --- Ejecuci√≥n del Componente ---
echo "üöÄ Iniciando la preparaci√≥n de datos local para ${PAIR}..."
echo "   - Leyendo desde: ${INPUT_GCS_PATH}"
echo "   - Datos preparados se subir√°n a: ${OUTPUT_GCS_BASE_PATH}/${PAIR}"

# Invocamos el task del componente directamente
python -m src.components.data_preparation.task \
    --input-data-path "${INPUT_GCS_PATH}" \
    --output-gcs-path "${OUTPUT_GCS_BASE_PATH}" \
    --years-to-keep "${YEARS_TO_KEEP}" \
    --holdout-months "${HOLDOUT_MONTHS}"

echo "‚úÖ Preparaci√≥n de datos completada. Los archivos est√°n en GCS."
